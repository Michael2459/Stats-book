{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency tables\n",
    "In this notebook we look at the wealth data from chapter 1, where the data are presented in summary form as a frequency table, with individuals amalgamated into classes of wealth.  Data in this form are a little more difficult to analyse using Python and there are some advantages to sticking to Excel for this.\n",
    "\n",
    "However, we will show what can be done.  First we import the libraries we need, then the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('wealth.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check to see that that data have been correctly imported.  In this case we can look at all the data, as we have only have 13 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wealth_class</th>\n",
       "      <th>wealth</th>\n",
       "      <th>frequency</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0-</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1668</td>\n",
       "      <td>0.166800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10,000-</td>\n",
       "      <td>17.5</td>\n",
       "      <td>1318</td>\n",
       "      <td>0.087900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25,000-</td>\n",
       "      <td>32.5</td>\n",
       "      <td>1174</td>\n",
       "      <td>0.078300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40,000-</td>\n",
       "      <td>45.0</td>\n",
       "      <td>662</td>\n",
       "      <td>0.066200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50,000-</td>\n",
       "      <td>55.0</td>\n",
       "      <td>627</td>\n",
       "      <td>0.062700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60,000-</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1095</td>\n",
       "      <td>0.054800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>80,000-</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1195</td>\n",
       "      <td>0.059800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>100,000-</td>\n",
       "      <td>125.0</td>\n",
       "      <td>3267</td>\n",
       "      <td>0.065300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>150,000-</td>\n",
       "      <td>175.0</td>\n",
       "      <td>2392</td>\n",
       "      <td>0.047800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>200,000-</td>\n",
       "      <td>250.0</td>\n",
       "      <td>2885</td>\n",
       "      <td>0.028900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>300,000-</td>\n",
       "      <td>400.0</td>\n",
       "      <td>1480</td>\n",
       "      <td>0.007400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>500,000-</td>\n",
       "      <td>750.0</td>\n",
       "      <td>628</td>\n",
       "      <td>0.001300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1,000,000-</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>198</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2,000,000-</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>88</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    wealth_class  wealth  frequency   density\n",
       "0            0-      5.0       1668  0.166800\n",
       "1       10,000-     17.5       1318  0.087900\n",
       "2       25,000-     32.5       1174  0.078300\n",
       "3       40,000-     45.0        662  0.066200\n",
       "4       50,000-     55.0        627  0.062700\n",
       "5       60,000-     70.0       1095  0.054800\n",
       "6       80,000-     90.0       1195  0.059800\n",
       "7      100,000-    125.0       3267  0.065300\n",
       "8      150,000-    175.0       2392  0.047800\n",
       "9      200,000-    250.0       2885  0.028900\n",
       "10     300,000-    400.0       1480  0.007400\n",
       "11     500,000-    750.0        628  0.001300\n",
       "12   1,000,000-   1500.0        198  0.000100\n",
       "13   2,000,000-   3000.0         88  0.000044"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data look OK.  First we calculate the average wealth.  We cannot just calculate the average of the 'wealth' column as this will not take account of the different frequencies in each class.  To demonstrate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "465.35714285714283"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['wealth'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is clearly not the right answer.  We could write some code to calculate the correct average, as one would do in Excel.  For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tot_wealth'] = df['wealth'] * df['frequency']\n",
    "ave_wealth = df['tot_wealth'].sum()/df['frequency'].sum()\n",
    "print(ave_wealth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first line calculates a new column, containing the total wealth of each group.  The second line calculates the mean, effectively calculating $\\frac{\\Sigma fx}{\\Sigma f}$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A simpler alternative is to use numpy's weighted average method, using the frequency column as weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.average(df['wealth'], weights=df['frequency'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives the same, correct answer.  Beyond this, things become more difficult.  There is not a simple command to calculate a standard deviation of grouped data, it has to be calculated as it would in Excel.  Here is some code that calculates the mean (again), variance and standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ave_wealth = df['tot_wealth'].sum()/df['frequency'].sum()\n",
    "df['fx_squared'] = df['tot_wealth'] * df['wealth']                         # Create the 'fx_squared' column\n",
    "var = (df['fx_squared'].sum()/df['frequency'].sum()) - ave_wealth**2       # Standard variance formula\n",
    "sd = var**0.5\n",
    "print('Mean =', ave_wealth, '\\nVar =', var, '\\nsd =', sd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us the correct answers but takes a little work (one could write a Python function to do all of it) and we still haven't got the median and quartiles.\n",
    "We could, however, trick the computer by pretending we have all the individual observations.  For this we create 1668 rows of individuals with £5000 of wealth, 1318 observations of wealth £17500, etc.  It is not the same as the original survey data but then nor is the frequency table.\n",
    "Doing this requires some code which we won't explain in detail.  (If interested, our source is here: https://serhiipuzyrov.com/2019/07/3-helpful-functions-for-data-manipulation-python/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def ungrouping(df, freq):\n",
    "    df = df.copy(deep=True)\n",
    "    df = df.loc[np.repeat(df.index.values,df[freq])\n",
    "               ].reset_index(drop=True)\n",
    "    df[freq] = 1\n",
    "    return df\n",
    "\n",
    "df2 = ungrouping(df, 'frequency')\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has created a new dataframe, df2, which has 18677 observations, which is the same as the sum of the frequencies in the frequency table.  Now we can simply use the 'describe' method to get our summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('precision', 3)\n",
    "df2['wealth'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives the correct answers for the mean and standard deviation.  The median and quartiles are approximately the same as in the book, the differences due to the fact that 'describe' is using the midpoint of the relevant class interval whereas our formula in the book allows us to obtain a better estimate within the interval.  The figures here are still useful as a fairly accurate guide."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The bar chart\n",
    "How we can obtain a bar chart or histogram of the data?  A bar chart, as in Figure 1. of the book, is easy to produce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(df['wealth_class'], df['frequency'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels on the x-axis need attention as they are currently unreadable but since we know this graph is inaccurate we will not bother to correct it here.\n",
    "We could do slightly better by plotting the frequency densities rather than the frequencies.  Again, this is easy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(df['wealth_class'], df['density'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives a slightly better picture, at least it is less misleading.  Drawing a correct histogram would require stretching the x-axis, for which the code would be complicated.  Hence we do not go further into this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suggested exercises\n",
    "1. Write some code to calculate the skewness statistic, as in the book (equation 1.28).  You should get the same answer, 5.898.  Be careful to use dataframe df, not df2.  (Hint: calculate a new column 'fx_cubed' then adapt the code above for the variance and sd.\n",
    "2. Add a title to the bar chart and try to fix the labels on the x-axis."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
